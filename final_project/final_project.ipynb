{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, f1_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import BernoulliRBM\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "sys.path.append(\"../tools/\")\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data, test_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the feature that I want to use in the classifier. I will use 'bonus','poi_related_messages' and 'from_messages_poi_ratio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_list = ['poi', 'bonus', 'poi_related_messages', 'from_messages_poi_ratio']  # You will need to use more features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset and create a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 'NaN',\n",
       " 'deferral_payments': 'NaN',\n",
       " 'deferred_income': 'NaN',\n",
       " 'director_fees': 'NaN',\n",
       " 'email_address': 'NaN',\n",
       " 'exercised_stock_options': 'NaN',\n",
       " 'expenses': 'NaN',\n",
       " 'from_messages': 'NaN',\n",
       " 'from_poi_to_this_person': 'NaN',\n",
       " 'from_this_person_to_poi': 'NaN',\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 'NaN',\n",
       " 'other': 362096,\n",
       " 'poi': False,\n",
       " 'restricted_stock': 'NaN',\n",
       " 'restricted_stock_deferred': 'NaN',\n",
       " 'salary': 'NaN',\n",
       " 'shared_receipt_with_poi': 'NaN',\n",
       " 'to_messages': 'NaN',\n",
       " 'total_payments': 362096,\n",
       " 'total_stock_value': 'NaN'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.pop(\"TOTAL\", 0)\n",
    "data_dict.pop(\"LOCKHART EUGENE E\", 0)\n",
    "data_dict.pop(\"THE TRAVEL AGENCY IN THE PARK\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_features(original_data_dict):\n",
    "    \"\"\"\n",
    "    adds new features to de dictionary\n",
    "    \"\"\"\n",
    "    for name in original_data_dict:\n",
    "        try:\n",
    "            if original_data_dict[name][\"from_poi_to_this_person\"] != 'NaN':\n",
    "                original_data_dict[name]['from_messages_poi_ratio'] = 1. * original_data_dict[name][\"from_poi_to_this_person\"] / original_data_dict[name][\n",
    "                    \"from_messages\"]\n",
    "            else:\n",
    "                original_data_dict[name]['from_messages_poi_ratio'] = 0\n",
    "\n",
    "            if original_data_dict[name][\"from_this_person_to_poi\"] != 'NaN':\n",
    "                original_data_dict[name]['person_to_poi_ratio'] = 1. * original_data_dict[name][\"from_this_person_to_poi\"] / original_data_dict[name][\n",
    "                    \"to_messages\"]\n",
    "            else:\n",
    "                original_data_dict[name]['person_to_poi_ratio'] = 0\n",
    "\n",
    "            poi_related_messages = original_data_dict[name][\"from_poi_to_this_person\"] + original_data_dict[name][\"from_this_person_to_poi\"] + \\\n",
    "                                   original_data_dict[name][\"shared_receipt_with_poi\"]\n",
    "            if 'NaN' not in poi_related_messages:\n",
    "                original_data_dict[name]['poi_related_messages'] = poi_related_messages\n",
    "            else:\n",
    "                original_data_dict[name]['poi_related_messages'] = 0\n",
    "        except:\n",
    "            original_data_dict[name]['poi_related_messages'] = 0\n",
    "\n",
    "    return original_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_clf_list():\n",
    "    \"\"\"\n",
    "    Instantiates all classifiers of interstes to be used.\n",
    "    \"\"\"\n",
    "    # List of tuples of a classifier and its parameters.\n",
    "    clf_list = []\n",
    "\n",
    "    #\n",
    "    clf_naive = GaussianNB()\n",
    "    params_naive = {}\n",
    "    clf_list.append((clf_naive, params_naive))\n",
    "\n",
    "    #\n",
    "    clf_tree = DecisionTreeClassifier()\n",
    "    params_tree = {\"min_samples_split\": [2, 5, 10, 20],\n",
    "                   \"criterion\": ('gini', 'entropy')\n",
    "                   }\n",
    "    clf_list.append((clf_tree, params_tree))\n",
    "\n",
    "    #\n",
    "    clf_linearsvm = LinearSVC()\n",
    "    params_linearsvm = {\"C\": [0.5, 1, 5, 10, 100, 10 ** 10],\n",
    "                        \"tol\": [10 ** -1, 10 ** -10],\n",
    "                        \"class_weight\": ['balanced']\n",
    "\n",
    "                        }\n",
    "    clf_list.append((clf_linearsvm, params_linearsvm))\n",
    "\n",
    "    #\n",
    "    clf_adaboost = AdaBoostClassifier()\n",
    "    params_adaboost = {\"n_estimators\": [20, 25, 30, 40, 50, 100]\n",
    "                       }\n",
    "    clf_list.append((clf_adaboost, params_adaboost))\n",
    "\n",
    "    #\n",
    "    clf_random_tree = RandomForestClassifier()\n",
    "    params_random_tree = {\"n_estimators\": [2, 3, 5],\n",
    "                          \"criterion\": ('gini', 'entropy')\n",
    "                          }\n",
    "    clf_list.append((clf_random_tree, params_random_tree))\n",
    "\n",
    "    #\n",
    "    clf_knn = KNeighborsClassifier()\n",
    "    params_knn = {\"n_neighbors\": [2, 3, 4, 5, 6, 7, 8, 9], \"p\": [2, 3, 4]}\n",
    "    clf_list.append((clf_knn, params_knn))\n",
    "\n",
    "    #\n",
    "    clf_log = LogisticRegression()\n",
    "    params_log = {\"C\": [0.05, 0.5, 1, 10, 10 ** 2, 10 ** 5, 10 ** 10, 10 ** 20],\n",
    "                  \"tol\": [10 ** -1, 10 ** -5, 10 ** -10],\n",
    "                  \"class_weight\": ['balanced']\n",
    "                  }\n",
    "    clf_list.append((clf_log, params_log))\n",
    "\n",
    "    #\n",
    "    clf_lda = LinearDiscriminantAnalysis()\n",
    "    params_lda = {\"n_components\": [0, 1, 2, 5, 10]}\n",
    "    clf_list.append((clf_lda, params_lda))\n",
    "\n",
    "    #\n",
    "    logistic = LogisticRegression()\n",
    "    rbm = BernoulliRBM()\n",
    "    clf_rbm = Pipeline(steps=[('rbm', rbm), ('logistic', logistic)])\n",
    "    params_rbm = {\n",
    "        \"logistic__tol\": [10 ** -10, 10 ** -20],\n",
    "        \"logistic__C\": [0.05, 0.5, 1, 10, 10 ** 2, 10 ** 5, 10 ** 10, 10 ** 20],\n",
    "        \"logistic__class_weight\": ['balanced'],\n",
    "        \"rbm__n_components\": [2, 3, 4]\n",
    "    }\n",
    "    clf_list.append((clf_rbm, params_rbm))\n",
    "\n",
    "    return clf_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_best_clf():\n",
    "    # type: () -> GridSearchCV\n",
    "    \"\"\"\n",
    "    Search for the best classifier and return it\n",
    "    :rtype: GridSearchCV\n",
    "    \"\"\"\n",
    "    f1score = 0\n",
    "    best_clf = None\n",
    "    for clftemp, params in setup_clf_list():\n",
    "        scorer = make_scorer(f1_score)\n",
    "        clftemp = GridSearchCV(clftemp, params, scoring=scorer)\n",
    "        clftemp = clftemp.fit(features_train, labels_train)\n",
    "        pred = clftemp.predict(features_test)\n",
    "        f1_score_temp = f1_score(labels_test, pred)\n",
    "        if f1_score_temp > f1score:\n",
    "            f1score = f1_score_temp\n",
    "            best_clf = clftemp.best_estimator_\n",
    "\n",
    "    pred = best_clf.predict(features_test)\n",
    "    return best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_dataset = add_features(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features and labels from dataset for local testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = featureFormat(my_dataset, features_list, sort_keys=True)\n",
    "labels, features = targetFeatureSplit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into test and feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = \\\n",
    "    train_test_split(features, labels, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the search for a best classifier and then call the ***test_classifier*** function to get the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, class_weight='balanced', dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=1e-10, verbose=0, warm_start=False)\n",
      "\tAccuracy: 0.77690\tPrecision: 0.45444\tRecall: 0.57600\tF1: 0.50805\tF2: 0.54675\n",
      "\tTotal predictions: 10000\tTrue positives: 1152\tFalse positives: 1383\tFalse negatives:  848\tTrue negatives: 6617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = search_best_clf()\n",
    "dump_classifier_and_data(clf, my_dataset, features_list)\n",
    "test_classifier(clf, my_dataset, features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}